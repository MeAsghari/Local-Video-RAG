# ğŸ¬ Local Video RAG: Edge AI Search Engine

> A smart, fast, and completely local video search engine running entirely on CPU.
> 
> No internet required. No GPU needed. Privacy-first.

## ğŸ“‹ Overview

**Local Video RAG** is an advanced video retrieval system that allows you to search through your personal or security footage using **natural language**. Instead of searching by filenames or timestamps, simply ask: _"The moment the cat is playing"_ or _"Where is the red car?"_.

This project features a **Hybrid C++/Python Architecture** to strike the perfect balance between **performance** (video processing) and **flexibility** (user interface). The core indexing engine is optimized using **C++** and **ONNX Runtime** to run efficiently on standard laptop CPUs.

### âœ¨ Key Features

-   ğŸš€ **High Performance:** Utilizes C++ for rapid frame extraction and preprocessing.
    
-   ğŸ§  **Edge AI:** Runs state-of-the-art AI models (CLIP) on CPU using **Int8 Quantization** (reducing RAM usage by ~4x).
    
-   ğŸ” **Semantic Search:** Deep understanding of content (objects, actions, colors) using Vision-Language models.
    
-   ğŸ“ˆ **Smart Smoothing:** Custom "Temporal Sliding Window" algorithm to increase detection accuracy and reduce noise.
    
-   ğŸ”’ **Privacy First:** All processing happens locally on your device; no data is sent to the cloud.
    
-   ğŸ¥ **Instant Playback:** Automatically generates an HTML player to jump to the exact timestamp of the result.
    

## ğŸ“º Demo

Watch how the system performs on a sample video:


## ğŸ— System Architecture

The system consists of two main components:

1.  **The Indexer (C++):**
    
    -   Reads video frame-by-frame using `OpenCV`.
        
    -   Extracts keyframes and performs preprocessing (Normalization/Resizing).
        
    -   Converts each frame into a mathematical vector (Embedding) using `ONNX Runtime` and a quantized CLIP model.
        
    -   Serializes data into a compact binary file (`video_index.bin`).
        
2.  **The Searcher (Python):**
    
    -   Accepts text queries from the user.
        
    -   Performs semantic search on the binary database using Cosine Similarity.
        
    -   Applies **Temporal Smoothing** to identify the best time window.
        
    -   Displays results in a rich CLI interface and launches the HTML player.
        

## ğŸ›  Prerequisites & Installation

Due to the optimized nature of the project, some large files (models, C++ libs) are not included in the repo. Please follow these steps:

### 1\. Clone the Repository

### 2\. Model Setup

We use a CLIP model optimized for CPU.

-   Run the notebook `Load-Model.ipynb`.
    
-   This script downloads the model, exports it to **ONNX**, and applies **Int8 Quantization**.
    
-   _Output:_ A `model_quantized.onnx` file will be created in the `models` directory.
    

### 3\. C++ Dependencies

To build the project, you need to download and place the following libraries in the project root (or set paths in `CMakeLists.txt`):

-   **OpenCV** (Version 4.x)
    
-   **ONNX Runtime** (C++ Version - preferably 1.16+)
    

### 4\. Build the Project

    mkdir build
    cd build
    cmake ..
    cmake --build . --config Release
    

### 5\. Python Requirements

    pip install torch transformers numpy rich opencv-python
    

## ğŸš€ Usage

### Step 1: Index the Video

Place your video file (e.g., `test.mp4`) next to the generated executable (`Local-Video-RAG.exe`) and run:

    ./Local-Video-RAG.exe
    

_Result:_ A `video_index.bin` file containing your video's embeddings will be generated.

### Step 2: Search

Run the Python script to enter the interactive search interface:

    python search_engine.py
    

Then ask anything!

> ğŸ” **Search:** "a girl reading a book"
> 
> ğŸ‘‰ **Result:** Found near 00:05 (Confidence: 75%)

## ğŸ“‚ File Structure

    Edge-Video-Semantic-Search/
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ main.cpp           # Main Indexer source code (C++)
    â”‚   â””â”€â”€ search_engine.py   # Search Interface (Python)
    â”œâ”€â”€ models/                # ONNX models location (generated by notebook)
    â”œâ”€â”€ build/                 # Compiled outputs (Exe, Binary Index)
    â”œâ”€â”€ necessary-files/       # Runtime requirements (DLLs, Test Video)
    â”œâ”€â”€ Local-Video-RAG-Report.docx  # Full technical report
    â”œâ”€â”€ Load-Model.ipynb       # Model download & quantization script
    â”œâ”€â”€ CMakeLists.txt         # C++ Build configuration
    â””â”€â”€ README.md              # Project documentation
    

## ğŸ§  Technical Highlights

### 1\. Int8 Quantization

We converted the CLIP model from Float32 (~600MB) to Int8 (~140MB). This allows the model to run significantly faster on CPUs and optimizes cache usage, making it feasible for edge devices.

### 2\. Temporal Smoothing (Sliding Window)

Raw search scores can be noisy. We implemented a **Moving Average Window** (size=3). This means if an object appears in 3 consecutive keyframes, its score is boosted. This technique significantly improves accuracy for actions (like "running" or "laughing") vs. static objects.

## ğŸ”® Future Work

-   Add **CUDA Execution Provider** support for GPU acceleration.
    
-   Integrate **Whisper** models for audio/speech search within videos.
    
-   Support for **RTSP Live Streams** (CCTV integration).
    

## ğŸ‘¨â€ğŸ’» Author

**Mahdi Asghari** - AI R&D Engineer

-   **Specialization:** Edge AI, C++ Optimization, Computer Vision.
    
-   **LinkedIn:** [Mahdi Asghari](https://www.google.com/search?q=https://www.linkedin.com/in/mahdi-asghari1996 "null")
    
-   **Instagram:** mahdiasghari.ai
    

